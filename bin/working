#!/usr/bin/env python3.2

import csv, argparse, operator, sys, datetime, time, random, os.path, json, hypy as hy
from math import log10
#from scipy import stats
from hivclustering import *

#-------------------------------------------------------------------------------		
def explore_tns_stability (network, outdeg, from_d, to_d, step):
    tns_by_d = {}
    node_names = None
    
    d = from_d
    
    while d <= to_d:
        fitted_degrees = {}
        print (d)
        print_network_evolution (network, fitted_degrees, outdeg, d, do_print = False)
        tns_by_d[d] = compute_tns (network, 2005, 2012, d, fitted_degrees, outdeg, do_print = False)
        if node_names is None:
            node_names = tns_by_d[d].keys()
            
        d += step
    
    distances = tns_by_d.keys()

    print ("Node,distance,TNS")
    
    for n in node_names:
        for d in distances:
            print (n,',',d,',',tns_by_d[d][n]['tns'])

#-------------------------------------------------------------------------------		

def import_edi (file):
	edi_by_id = {}
	ediReader = csv.reader(file)
	header = next(ediReader)
	if len (header) != 14:
		raise Exception ('Expected a .csv file with 14 columns as input')
	
	for line in ediReader:
		if len (line[1]): # has PID
			id = line[1].replace ('-','')
		else:
			id = line[0]
		
		geno_date = None
		if len (line[2]): # geno
			geno_date = time.strptime (line[2],'%m/%d/%Y')
		
		
		drug_date = None
		if len (line[4]): # drugz
			drug_date = time.strptime (line[4],'%m/%d/%Y')
			
		edi_date = None
		if len (line [6]): # edi
			edi_date = time.strptime (line[6],'%m/%d/%Y')
			
		naive 	 = False
		if line[3] == 'ARV Naive':
			naive = True
			
		if geno_date and edi_date:
			if edi_date > geno_date:
				#print time.mktime(edi_date) - time.mktime(geno_date)
				
				part1 = time.strftime ("%m/%d",edi_date)
				part2 = time.strftime ("%Y",geno_date)
				new_edi_date = time.strptime ("/".join((part1,part2)),'%m/%d/%Y')
				#edi_date.tm_year = geno_date.tm_year
				if new_edi_date > geno_date:
					continue
				else:	
					edi_date = new_edi_date
				
		viral_load = None
		if len (line [8]): # vl
			viral_load = int (line[8])
			
		edi_by_id [id] = [geno_date, drug_date, edi_date, viral_load, naive]
		#if (edi_date and drug_date and edi_date > drug_date):
		#	print "Fail %s" % id, edi_date, drug_date
		
	return edi_by_id

#-------------------------------------------------------------------------------		

def get_dot_string_vl (self, year_vis = None):    
    shape = 'ellipse' 
    color = 'white'
    label = ''#str(self.get_baseline_date()) 
    
    edi_info = self.get_treatment_since_edi()
    
    is_mi = False
    '''for k in self.attributes:
        if k.find ('|CI') >= 0 or k.find ('|SI') >=0:
            #print ('MI!')
            is_mi = True
            shape = 'doubleoctagon'
            break
    '''
    
    if self.get_sample_count() > 1:
        shape = 'rect'
    
    color = 'white'
    
    if self.vl is not None:
       color = '/reds9/%d' % (round(log10 (self.vl)))
        
        
    if year_vis is not None:
        if self.get_baseline_date () > year_vis:
            return '"%s" [label = "%s", fillcolor = "%s", shape = %s, style = "invis"];\n' % (self.id, label , color, shape)
        
    return '"%s" [label = "%s", fillcolor = "%s", shape = %s];\n' % (self.id, label , color, shape)

#-------------------------------------------------------------------------------		

def generate_dot_454 (self, file, year_vis = None, reduce_edges = True):
    file.write ('digraph G { overlap="voronoi";\n outputorder = edgesfirst;\nnode[style=filled];\n');
    nodes_drawn = {}
    
    directed = {'undirected':0, 'directed':0}
    
    for edge in self.edges if reduce_edges == False else self.reduce_edge_set():
        if edge.visible:
            distance = self.edges[edge]
            
            if edge.p1 not in nodes_drawn:
                nodes_drawn[edge.p1] = edge.p1.get_baseline_date()
                file.write (edge.p1.get_dot_string(year_vis))
            if edge.p2 not in nodes_drawn:
                nodes_drawn[edge.p2] = edge.p2.get_baseline_date()
                file.write (edge.p2.get_dot_string(year_vis))
            
            year_diff = abs(edge.date1.tm_year - edge.date2.tm_year)
            if isinstance(edge.compute_direction(),type(None)):
                directed ['undirected'] += 1
            else:
                directed ['directed'] += 1
            edge_attr = edge.direction()
            
            if year_vis is not None:
                if edge.check_date (year_vis) == False:
                    file.write ('%s [style="invis" arrowhead = "%s"];\n' % (edge_attr[0], edge_attr[1]));
                    continue
                    
            color = 'red' if edge.has_attribute ('UDS') else 'black'   
            file.write ('%s [style="bold" color = "%s" label = "%s" arrowhead = "%s"];\n' % (edge_attr[0], color, edge.label(), edge_attr[1]));

    file.write ("\n};")
    return directed    
 
#-------------------------------------------------------------------------------		

def print_network_evolution (network, store_fitted = None, outdegree = False, distance = None, do_print = True):
    byYear = []
    
    for year in range (2000,2013):
        network.clear_filters ()
        network.apply_date_filter (year, do_clear= True)
        if distance is not None:
           network.apply_distance_filter (distance, do_clear = False)
        network_stats = network.get_edge_node_count ()
        network.compute_clusters()
        clusters = network.retrieve_clusters()
        if outdegree:
            distro_fit = network.fit_degree_distribution ('outdegree')        
        else:
            distro_fit = network.fit_degree_distribution ()
        #print ("Best distribution is '%s' with rho = %g" % (distro_fit['Best'], 0.0 if distro_fit['rho'][distro_fit['Best']] is None else  distro_fit['rho'][distro_fit['Best']]), distro_fit['degrees'])
        if store_fitted is not None:
            store_fitted [year] = distro_fit['fitted']['Waring']
        byYear.append ([year, network_stats['nodes'], network_stats['edges'], network_stats['total_sequences'],len(clusters),max ([len (clusters[c]) for c in clusters if c is not None]),distro_fit['rho']['Waring']])
    
    #print (distro_fit)
    
    if do_print:
        print ("\nYear,Nodes,Edges,Sequences,Clusters,MaxCluster,rho");
        for row in byYear:
            print (','.join([str (k) for k in row]))
 
#-------------------------------------------------------------------------------		
def print_degree_distro (network):
    print ("\t".join (['degree','rawcount','rawpred','count','pred','ccount','cpred']))
    total = float(sum(distro_fit['degrees']));
    total1 = 0.
    total2 = 0.
    for k in range (0, len(distro_fit['degrees'])): 
        vec = [str(p) for p in [k+1,distro_fit['degrees'][k],distro_fit['fitted']['Waring'][k]*total,distro_fit['degrees'][k]/total,distro_fit['fitted']['Waring'][k]]]
        vec.extend ([0.,0.])
        total1 += distro_fit['degrees'][k]/total
        total2 += distro_fit['fitted']['Waring'][k]
        vec[5] = str(total1)
        vec[6] = str(total2)
        print ("\t".join (vec))
    
    for dname,rho in distro_fit['rho'].items():
        print ("%s : rho = %s, BIC = %s, p = %s" % (dname, 'N/A' if rho is None else "%5.2f" % (rho) , 'N/A' if distro_fit["BIC"][dname] is None else "%7.2f" % distro_fit["BIC"][dname], 'N/A' if distro_fit["p"][dname] is None else "%4.2f" % (distro_fit["p"][dname])))

#-------------------------------------------------------------------------------		
def print_degree_table (network, year_from, year_to, distance = 0.015):
    by_id = {}
    
    sep = '\t'
    
    for node in network.nodes:
        by_id [node.id] = []
    
    for year in range (year_from,year_to):
        network.clear_filters ()
        network.apply_distance_filter (distance)
        network.apply_date_filter (year,False)
        degree_list = network.get_node_degree_list(year,True)
        network.clear_adjacency()
        network.apply_date_filter (year,False)
        cluster_size = network.cluster_size_by_node()

        for k in degree_list: 
            if degree_list [k] is None:
                by_id [k.id].append('.')
            else:
                by_id [k.id].append(str (degree_list [k]) + '|' + str (cluster_size[k]))
    
    print  ('ID%s%s' % (sep,sep.join([str (y) for y in  range (year_from,year_to)])))
    
    for node in by_id:
        print ('%s%s%s'%(node,sep,sep.join (by_id[node])))   
        
#-------------------------------------------------------------------------------		

def tns (degree, cluster_size, fitted = None):
    if fitted is not None:
        deg_sum = sum(fitted[0:degree])
        return deg_sum
        if deg_sum < 0.5:
            deg_cont = 0
        else:
            if deg_sum < 0.9:
                deg_cont = 1
            else:
                if deg_sum < 0.95:
                    deg_cont = 2
                else:
                   if deg_sum < 0.99:
                        deg_cont = 3
                   else:
                        deg_cont = 4
        return deg_cont #+ log10 (cluster_size)
    else:
        return float(degree+1)**(1./3) + log10 (cluster_size)
        
#-------------------------------------------------------------------------------		
def compute_tns (network, year_from, year_to, distance = 0.015, fitted = None, outdegree = False, do_print = True):
    by_id = {}

    for year in range (year_from,year_to):
        network.clear_filters ()
        network.apply_distance_filter (distance)
        network.apply_date_filter (year,False)
            
        degree_list = network.get_node_degree_list(year,True)
        
        network.clear_adjacency()
        network.apply_date_filter (year,False)
        cluster_size = network.cluster_size_by_node()
        
        degree_index = 1 if outdegree else 3
        
        #if year < year_to-1:
        if True:
            for node in degree_list:
                if node.get_baseline_date () == year and year < year_to - 1:
                    by_id [node.id] = {}
                    tns_s = tns (degree_list[node][degree_index],cluster_size[node], None if fitted is None else fitted[year])
                    #print ("%d,%s,%s,%d,%d" % (year, node.id, str(degree_list[node]), cluster_size[node], tns_s))
                    by_id[node.id]['tns'] = tns_s
                    by_id[node.id]['deg'] = degree_list[node][degree_index]
                    by_id[node.id]['cls'] = cluster_size[node]
                    by_id[node.id]['year'] = float (year)
                else:
                    if year > year_from and node.get_baseline_date () == year - 1:
                        if cluster_size[node] - by_id[node.id]['cls'] > 0:
                            by_id[node.id]['cls'] = (degree_list[node][degree_index] - by_id[node.id]['deg'])/(cluster_size[node] - by_id[node.id]['cls'])
                        else:
                            by_id[node.id]['cls'] = 0
                        by_id[node.id]['deg'] = degree_list[node][degree_index] - by_id[node.id]['deg']
                         
                        
                        
        else:
            for node in degree_list:
                if (node.id in by_id):
                     #print (by_id[node.id])
                     by_id[node.id]['deg'] = (degree_list[node][3] - by_id[node.id]['deg'])/(year_to-by_id[node.id]['year'])
        
         
    if do_print:     
        print ("id,TNS,deg,cls")
        for k in by_id:
            print (k, ',', by_id[k]['tns'], ',', by_id[k]['deg'], ',', by_id[k]['cls'])
            '''if (by_id[k]['cls'] > 1):
                print (k, file = sys.stderr)
            '''
    return by_id
               
#-------------------------------------------------------------------------------		

patient.get_dot_string = get_dot_string_vl
transmission_network.generate_dot = generate_dot_454

random.seed ()

arguments = argparse.ArgumentParser(description='Read filenames.')

arguments.add_argument('-i', '--input',   help = 'Input CSV file with inferred genetic links (or stdin if omitted). Must be a CSV file with three columns: ID1,ID2,distance.')
arguments.add_argument('-u', '--uds',   help = 'Input CSV file with UDS data. Must be a CSV file with three columns: ID1,ID2,distance.')
arguments.add_argument('-d', '--dot',   help = 'Output DOT file for GraphViz (or stdout if omitted)')
arguments.add_argument('-c', '--cluster', help = 'Output a CSV file with cluster assignments for each sequence', required = True)
arguments.add_argument('-t', '--threshold', help = 'Only count edges where the distance is less than this threshold')
arguments.add_argument('-e', '--edi',   help = 'A .csv file with EDI dates')
arguments.add_argument('-f', '--format',   help = 'Sequence ID format. One of AEH (ID | sample_date | otherfiels default), LANL (e.g. B_HXB2_K03455_1983 : subtype_country_id_year -- could have more fields), plain (treat as sequence ID only, no meta)')
arguments.add_argument('-x', '--exclude',   help = 'Exclude any sequence which belongs to a cluster containing a "reference" strain, defined by the year of isolation. The value of this argument is an integer year (e.g. 1983) so that any sequence isolated in or before that year (e.g. <=1983) is considered to be a lab strain. This option makes sense for LANL or AEH data.')

settings = arguments.parse_args()

if settings.input == None:
	settings.input = sys.stdin
else:
	try:
		settings.input = open (settings.input, 'r')
	except IOError:
		print ("Failed to open '%s' for reading" % (settings.input))
		raise
	
if settings.dot == None:
	settings.dot = sys.stdout
else:
	try:
		settings.dot = open (settings.dot, 'w')
	except IOError:
		print ("Failed to open '%s' for writing" % (settings.dot))
		raise
		
	
edi = None

if settings.edi is not None:
	try:
		settings.edi = open (settings.edi, 'r')
		edi = import_edi (settings.edi)
	except IOError:
		print ("Failed to open '%s' for reading" % (settings.edi))
		raise

try:
	settings.cluster = open (settings.cluster, 'w')
except IOError:
	print ("Failed to open '%s' for writing" % (settings.cluster))
	raise
	
formatter = parseAEH

if settings.format is not None:
	formats = {"AEH" : parseAEH, "LANL": parseLANL, "plain": parsePlain}
	try:
		formatter = formats[settings.format]
	except KeyError:
		print ("%s is not a valid setting for 'format' (must be in %s)" % (settings.edi,str(list(formats.keys()))))
		raise
		
if settings.exclude is not None:
	try:
		settings.exclude = datetime.datetime (int (settings.exclude), 12, 31)	
	except ValueError:
		print ("Invalid contaminant threshold year '%s'" % (settings.exclude))
		raise 


if settings.threshold is not None:
	settings.threshold = float (settings.threshold)


if settings.uds is not None:
	try:
		settings.uds = open (settings.uds, 'r')
	except IOError:
		print ("Failed to open '%s' for reading" % (settings.uds))
		raise
		
network         = transmission_network ()
network.read_from_csv_file (settings.input, formatter, settings.threshold)


if settings.uds:
    network.read_from_csv_file (settings.uds, formatter, settings.threshold, 'UDS')

network_stats = network.get_edge_node_count ()
sys.setrecursionlimit(max(sys.getrecursionlimit(),network_stats['nodes']))	 

if edi is not None:	 
    network.add_edi (edi)
    print ("Added edi information to %d nodes" % len ([k for k in network.nodes if k.edi is not None]))
   

network.compute_clusters()
clusters = network.retrieve_clusters ()

if settings.exclude is not None:
	remove_these_ids = []
	for c in clusters:
		for node in clusters[c]:
			if tm_to_datetime (node.dates[0]) <= settings.exclude:
				if node.cluster_id not in remove_these_ids:
					remove_these_ids.append(node.cluster_id)
		
	print ("Removing %d clusters with contaminant sequences" % len (remove_these_ids))
	network.apply_cluster_filter (remove_these_ids)
	network.compute_clusters()
	clusters = network.retrieve_clusters ()
	
network_stats = network.get_edge_node_count ()
print ("%d edges on %d nodes\n" % (network_stats['edges'], network_stats['nodes']))

if settings.threshold is None: 
    print ("%d nodes with multiple dates" % len (network_stats['multiple_dates']))
    minfo = network.report_multiple_samples (network_stats['multiple_dates'])
    print ("Samples per patient: %d-%d (median %d)" % (minfo['samples']['min'],minfo['samples']['max'],minfo['samples']['median']))
    print ("Duration per patient (wks): %d-%d (median %d)" % (minfo['followup']['min']/7,minfo['followup']['max']/7,minfo['followup']['median']/7))
    
    earliest = None
    latest   = None
    
    for k in network.nodes:
        first  = k.get_baseline_date(True)
        lastd = k.get_latest_date (True)
        
        if earliest is None or first < earliest:
            earliest = first
        if latest is None or lastd > latest:
            latest = lastd
    
    print ("%d/%d/%d -- %d/%d/%d" % (earliest.tm_year, earliest.tm_mon, earliest.tm_mday, latest.tm_year, latest.tm_mon, latest.tm_mday))
    
    with open ('baseline.csv', 'w') as fh:
        network.spool_pairwise_distances (fh, baseline = True)
    
    sys.exit(0)

network.compute_clusters()
clusters = network.retrieve_clusters()
print ("Found %d clusters" % len(clusters), file = sys.stderr)
print ("Maximum cluster size = %d nodes" % max ([len (clusters[c]) for c in clusters if c is not None]), file = sys.stderr)
directed = 0
reasons = {}
for an_edge in network.reduce_edge_set():
    if an_edge.compute_direction() is not None:
        directed += 1
    else:
        reason = an_edge.why_no_direction()
        if reason in reasons:
            reasons[reason] += 1
        else:
            reasons[reason] = 1

print ("%d directed edges" % directed)
print (reasons)

print ("Fitting the degree distribution to various densities", file = sys.stderr)
#print (network.get_degree_distribution())
distro_fit = network.fit_degree_distribution ()
print ("Best distribution is '%s' with rho = %g" % (distro_fit['Best'], distro_fit['rho'][distro_fit['Best']]))

# find diffs in directed edges
'''for anEdge in network.edges:
    if anEdge.visible:
        dir, diffr = anEdge.compute_direction (True)
        if dir is not None:
            print (diffr)
'''

network.generate_dot (settings.dot)
#print_degree_distro     (network)

outdeg = True

#explore_tns_stability (network, outdeg, 0.01, 0.0205, 0.001)



fitted_degrees = {}
#print_network_evolution (network, fitted_degrees, False, settings.threshold, True)
#print (fitted_degrees[2012])

print_network_evolution (network, fitted_degrees, outdeg, settings.threshold, False)
tns = compute_tns (network, 2005, 2012, settings.threshold, fitted_degrees, outdeg, False)

high_tns = ([k for k in tns if tns[k]['tns'] >= 0.5])
high_tns_degs = network.get_node_degree_list(None,False,high_tns)
high_tns_years = [pat.get_baseline_date() for pat in high_tns_degs]

node_neighs_out = {}
node_neighs_in  = {}

network.clear_filters()
network.apply_date_filter (2005)

high_degs = sorted(network.get_node_degree_list (None, False).items(), key=operator.itemgetter(1) )


for a_node in network.nodes:
    node_neighs_out [a_node] = network.get_node_neighborhood (a_node.id,False,True,False)
    node_neighs_in [a_node] = network.get_node_neighborhood (a_node.id,False,True,True)

treatment_runs = 1000

treated_tns = [len(network.simulate_treatment([patient(id) for id in high_tns],node_neighs_out,node_neighs_in)) for k in range (treatment_runs)]
tns_treat = describe_vector(treated_tns)
print (tns_treat)

print ([id for id in high_degs[-9:]])
treated_tns = [len(network.simulate_treatment([id[0] for id in high_degs[-9:]],node_neighs_out,node_neighs_in)) for k in range (treatment_runs)]
max_deg = describe_vector(treated_tns)
print (max_deg)

medians = []
better  = 0
for samp in range (1000):
    a_subset = network.sample_subset_year_list (high_tns_years)
    treated_tns = [len(network.simulate_treatment(a_subset,node_neighs_out,node_neighs_in)) for k in range (treatment_runs)]
    med_val = describe_vector(treated_tns)['median']
    medians.append(med_val)
    better += med_val >= tns_treat['median']
    print (better/len(medians))
    
print (describe_vector(medians))

'''
sampled_sum = (len([k for k in high_tns_degs.values() if k>=9]))

pv = 0
for k in range (100):
    a_subset = network.sample_subset_year_list (high_tns_years)
    #print ([pat.get_baseline_date() for pat in a_subset])
    pv += len([k for k in (network.get_node_degree_list(None,False,[pat.id for pat in a_subset]).values()) if k >=9]) > sampled_sum

print (sampled_sum, pv)
'''
def report_high_tns ():
    for aNode in tns:
        if tns[aNode]['tns']>= 0.5:
            high_tns_node = network.has_node_with_id (aNode)
            bsln = high_tns_node.get_baseline_date()
            print (aNode, bsln)
            network.clear_filters()
            print (network.apply_date_filter (bsln))
            network.compute_clusters ()
            print (network.apply_cluster_filter ([high_tns_node.cluster_id], exclude = False, do_clear = False))
            with open ('/Users/sergei/Dropbox/JAMA Network Paper/Figures/TNSExamples/%s_%d_cluster.dot' % (aNode, bsln), 'w') as fh:
                network.generate_dot (fh)
            network.clear_filters()
            network.compute_clusters ()
            print (network.apply_cluster_filter ([high_tns_node.cluster_id], exclude = False, do_clear = False))
            with open ('/Users/sergei/Dropbox/JAMA Network Paper/Figures/TNSExamples/%s_%d_cluster.dot' % (aNode, 2012), 'w') as fh:
                network.generate_dot (fh)
            continue
            print (network.apply_id_filter ([aNode]))
            with open ('/Users/sergei/Dropbox/JAMA Network Paper/Figures/TNSExamples/%s_%d.dot' % (aNode, bsln), 'w') as fh:
                network.generate_dot (fh)
            for year in range (bsln+1, 2012):
                network.clear_filters()
                network.apply_date_filter (year)
                network.apply_id_filter ([aNode])
                with open ('/Users/sergei/Dropbox/JAMA Network Paper/Figures/TNSExamples/%s_%d.dot' % (aNode, year), 'w') as fh:
                    network.generate_dot (fh)
            


